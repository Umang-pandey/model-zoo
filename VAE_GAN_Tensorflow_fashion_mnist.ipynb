{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE GAN-Tensorflow fashion_mnist",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQLdmlZlJT8MxTC/g4yAT7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Umang-pandey/model-zoo/blob/master/VAE_GAN_Tensorflow_fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1KGI6NsThML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense, Input, Lambda, Flatten, concatenate, Reshape, RepeatVector\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import pickle as pkl\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist,mnist\n",
        "from scipy.stats import norm\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "tensorboard=TensorBoard(log_dir=\"logdir/{}\".format(time()))\n",
        "\n",
        "class VAEGAN:\n",
        "\n",
        "  def __init__(self, digit_size, num_classes, latent_dim, sess_name=''):\n",
        "\n",
        "    self.sess = tf.compat.v1.Session()\n",
        "    self.digit_size = digit_size\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "    self.gamma = 1  # parameter of training\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "    self.a = tf.compat.v1.placeholder(tf.float32, shape=(None, self.digit_size, self.digit_size, 1))\n",
        "    self.b = tf.compat.v1.placeholder(tf.float32, shape=(None, num_classes))\n",
        "    self.c = tf.compat.v1.placeholder(tf.float32, shape=(None, latent_dim))\n",
        "\n",
        "    self.img = Input(tensor=self.a)\n",
        "    self.lbls = Input(tensor=self.b)\n",
        "    self.z = Input(tensor=self.c)\n",
        "    \n",
        "\n",
        "\n",
        "    #Encoder \n",
        "\n",
        "    with tf.compat.v1.variable_scope('encoder'):\n",
        "        x = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(self.img)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
        "        x = Flatten()(x)\n",
        "        x = concatenate([x, self.lbls])\n",
        "        h = Dense(64, activation='relu')(x)\n",
        "        self.z_mean = Dense(latent_dim)(h)\n",
        "        self.z_log_var = Dense(latent_dim)(h)\n",
        "        z = Lambda(self.sampler, output_shape=(latent_dim,))([self.z_mean, self.z_log_var])\n",
        "\n",
        "    self.encoder = Model([self.img, self.lbls], [self.z_mean, self.z_log_var, z])\n",
        "\n",
        "    #Decoder\n",
        "\n",
        "    with tf.compat.v1.variable_scope('decoder'):\n",
        "\n",
        "        x = concatenate([self.z, self.lbls])\n",
        "\n",
        "        x = Dense(7*7*128, activation='relu')(x)\n",
        "        x = Reshape((7, 7, 128))(x)\n",
        "        x = UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "        x = Conv2D(64, kernel_size=(5, 5), padding='same', activation='relu')(x)\n",
        "\n",
        "        x = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "        x = UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "        dec_output = Conv2D(1, kernel_size=(5, 5), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    self.decoder = Model([self.z, self.lbls], dec_output)\n",
        "\n",
        "    #Discriminator \n",
        "\n",
        "    with tf.compat.v1.variable_scope('discriminator'):\n",
        "\n",
        "      x = Conv2D(128, kernel_size=(7, 7), strides=(2, 2), padding='same', activation='relu')(self.img)\n",
        "      x = self.add_units_to_conv2d(x, self.lbls)\n",
        "\n",
        "      x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "      x = Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
        "      x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "      # layer for activations compare\n",
        "      l = Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "      h = Flatten()(x)\n",
        "      disc_output = Dense(1, activation='sigmoid')(h)\n",
        "\n",
        "    self.discriminator = Model([self.img, self.lbls], [disc_output, l])\n",
        "\n",
        "    #GAN \n",
        "\n",
        "    self.z_mean, self.z_log_var, encoded = self.encoder([self.img, self.lbls])\n",
        "\n",
        "    self.generated_img = self.decoder([encoded, self.lbls])\n",
        "\n",
        "    self.generated_from_z = self.decoder([self.z, self.lbls])\n",
        "\n",
        "    self.discr_real_img, self.d_l_real_img = self.discriminator([self.img, self.lbls])\n",
        "\n",
        "    self.discr_fake_img, self.d_l_fake_img = self.discriminator([self.generated_img, self.lbls])\n",
        "\n",
        "    self.discr_img_from_z, self.d_l_img_from_z = self.discriminator([self.generated_from_z, self.lbls])\n",
        "\n",
        "    #Define Losses \n",
        "\n",
        "    self.L_prior = - 0.5 * tf.reduce_sum(1. + \n",
        "      tf.clip_by_value(self.z_log_var, -2, 2) - tf.square(self.z_mean) - \n",
        "      tf.exp(tf.clip_by_value(self.z_log_var, -2, 2)), axis=-1) / self.digit_size / self.digit_size\n",
        "\n",
        "\n",
        "    self.L_Diss_Like = tf.reduce_sum(\n",
        "      tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=tf.sigmoid(self.d_l_real_img),\n",
        "        logits=self.d_l_fake_img)) / self.digit_size / self.digit_size\n",
        "\n",
        "    log_d_img   = tf.math.log(self.discr_real_img + 1e-10)\n",
        "    log_d_gen_img = tf.math.log(1. - self.discr_fake_img + 1e-10)\n",
        "    log_d_img_from_z = tf.math.log(1. - self.discr_img_from_z + 1e-10)\n",
        "\n",
        "    self.DiscrLoss = -1 / 4 * tf.reduce_sum(log_d_img + log_d_gen_img + log_d_img_from_z) / self.digit_size / self.digit_size\n",
        "\n",
        "    self.EncLoss = self.L_prior + self.L_Diss_Like\n",
        "    self.DecLoss = self.gamma * self.L_Diss_Like - self.DiscrLoss\n",
        "\n",
        "    #Optimizers \n",
        "    EncOpt =  tf.compat.v1.train.RMSPropOptimizer(0.001)\n",
        "    DecOpt = tf.compat.v1.train.RMSPropOptimizer(0.0003)\n",
        "    DiscrOpt = tf.compat.v1.train.RMSPropOptimizer(0.001)\n",
        "\n",
        "    Enc_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, 'encoder')\n",
        "    Dec_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, 'decoder')\n",
        "    Discr_vars = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, 'discriminator')\n",
        "\n",
        "    self.enc_step = EncOpt.minimize(self.EncLoss, var_list=Enc_vars)\n",
        "    self.dec_step = DecOpt.minimize(self.DecLoss, var_list=Dec_vars)\n",
        "    self.discr_step = DiscrOpt.minimize(self.DiscrLoss, var_list=Discr_vars)\n",
        "\n",
        "    self.saver = tf.compat.v1.train.Saver()\n",
        "\n",
        "    self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "    \n",
        "\n",
        "  def add_units_to_conv2d(self, conv2, units):\n",
        "    dim1 = int(conv2.shape[1])\n",
        "    dim2 = int(conv2.shape[2])\n",
        "    dimc = int(units.shape[1])\n",
        "    repeat_n = dim1*dim2\n",
        "    units_repeat = RepeatVector(repeat_n)(self.lbls)\n",
        "    units_repeat = Reshape((dim1, dim2, dimc))(units_repeat)\n",
        "    return concatenate([conv2, units_repeat])\n",
        "\n",
        "  def sampler(self, args):\n",
        "    z_mean, z_log_var = args\n",
        "    batch_size = K.shape(z_mean)[0]\n",
        "    dim = K.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape=(batch_size, dim))\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "  def vae_train_step(self, data_batch, lbls_batch, z):\n",
        "    l_prior, dec_image, l_dis_like, l_gan, _, _ = self.sess.run(\n",
        "      [self.L_prior, self.generated_from_z, self.L_Diss_Like, self.DiscrLoss, self.enc_step, self.dec_step],\n",
        "                      feed_dict={self.z:z, self.img:data_batch, self.lbls:lbls_batch, K.learning_phase():1})\n",
        "    return l_prior, dec_image, l_dis_like, l_gan\n",
        "\n",
        "  def discr_train_step(self, data_batch, lbls_batch, z):\n",
        "    loss, _ = self.sess.run([self.DiscrLoss, self.discr_step], \n",
        "                            feed_dict={self.img: data_batch,\n",
        "                                      self.lbls: lbls_batch,\n",
        "                                      self.z: z,\n",
        "                                      K.learning_phase(): 1})\n",
        "    return loss\n",
        "\n",
        "  def train(self, Images, Labels, batch_size, epochs, k_steps):\n",
        "\n",
        "    \n",
        "\n",
        "    for i in range(epochs):\n",
        "        # Select a random batch of images\n",
        "        idx = np.random.randint(0, Images.shape[0], batch_size)\n",
        "        imgs = Images[idx]\n",
        "        lbls = Labels[idx]\n",
        "        zp = np.random.randn(batch_size, latent_dim)\n",
        "\n",
        "        #Discriminator\n",
        "        discr_loss = 0\n",
        "        counter = 1\n",
        "        for j in range(k_steps):\n",
        "          loss = self.discr_train_step(imgs, lbls, zp)\n",
        "          # next minibatch\n",
        "          idx = np.random.randint(0, Images.shape[0], batch_size)\n",
        "          imgs = Images[idx]\n",
        "          lbls = Labels[idx]\n",
        "          zp = np.random.randn(batch_size, latent_dim)\n",
        "\n",
        "          discr_loss += loss\n",
        "\n",
        "          if loss < 1.0:\n",
        "            break\n",
        "\n",
        "          counter += 1\n",
        "\n",
        "\n",
        "        discr_loss /= counter\n",
        "\n",
        "        #VAE \n",
        "        vae_loss = 0\n",
        "        counter = 1\n",
        "        for j in range(k_steps):\n",
        "          l_prior, dec_image, l_dis_like, loss = self.vae_train_step(imgs, lbls, zp)\n",
        "          vae_loss += loss\n",
        "          if loss > 0.4:\n",
        "            break\n",
        "          # next minibatch\n",
        "          idx = np.random.randint(0, Images.shape[0], batch_size)\n",
        "          imgs = Images[idx]\n",
        "          lbls = Labels[idx]\n",
        "          zp = np.random.randn(batch_size, latent_dim)\n",
        "          counter += 1\n",
        "\n",
        "        vae_loss /= counter\n",
        "\n",
        "       # print (\"%d [D loss: %f] [G loss: %f]\" % (i+1, discr_loss, vae_loss))\n",
        "    print (\"[D loss: %f] [G loss: %f]\" % ( discr_loss, vae_loss))    \n",
        "        \n",
        "\n",
        "  def generate(self, z, lbl):\n",
        "    return self.sess.run(self.generator([self.z, self.lbls]), \n",
        "                        feed_dict={self.z: z,\n",
        "                                  self.lbls: lbl,\n",
        "                                  K.learning_phase(): 0})\n",
        "\n",
        "  def draw_manifold(self, lbl):\n",
        "        n = 15\n",
        "        # Draw samples from manifold\n",
        "        grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "        grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "        figure = np.zeros((self.digit_size * n, self.digit_size * n))\n",
        "        input_lbl = np.zeros((1, 10))\n",
        "        input_lbl[0, lbl] = 1\n",
        "        for i, yi in enumerate(grid_x):\n",
        "            for j, xi in enumerate(grid_y):\n",
        "                z_sample = np.zeros((1, self.latent_dim))\n",
        "                z_sample[:, :2] = np.array([[xi, yi]])\n",
        "\n",
        "                x_decoded = self.sess.run(self.decoder([self.z, self.lbls]), \n",
        "                                                          feed_dict={self.z: z_sample,\n",
        "                                                                    self.lbls: input_lbl,\n",
        "                                                                    K.learning_phase(): 0})\n",
        "                digit = x_decoded[0].squeeze()\n",
        "                figure[i * self.digit_size: (i + 1) * self.digit_size,\n",
        "                       j * self.digit_size: (j + 1) * self.digit_size] = digit\n",
        "\n",
        "        # Visualization\n",
        "        plt.figure(figsize=(10, 10), num='Manifold')\n",
        "        plt.imshow(figure, cmap='Greys_r')\n",
        "        plt.grid(False)\n",
        "        ax = plt.gca()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        plt.show()\n",
        "        return figure\n",
        "\n",
        "  def style_transfer(self, prototype, in_lbl, out_lbl):\n",
        "    rows = prototype.shape[0]\n",
        "    if isinstance(in_lbl, int):\n",
        "        lbl = in_lbl\n",
        "        in_lbl = np.zeros((rows, 10))\n",
        "        in_lbl[:, lbl] = 1\n",
        "    if isinstance(out_lbl, int):\n",
        "        lbl = out_lbl\n",
        "        out_lbl = np.zeros((rows, 10))\n",
        "        out_lbl[:, lbl] = 1\n",
        "    return self.vae.predict([prototype, in_lbl, out_lbl])\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) =mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test  = x_test .astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))\n",
        "y_train_cat = to_categorical(y_train).astype(np.float32)\n",
        "y_test_cat  = to_categorical(y_test).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# network parameters \n",
        "batch_size = 128\n",
        "epochs = 2000\n",
        "latent_dim = 10\n",
        "digit_size = 28\n",
        "num_classes = 10\n",
        "\n",
        "vaegan = VAEGAN(digit_size, num_classes, latent_dim)\n",
        "vaegan.train(x_train, y_train_cat, batch_size, epochs, 5)\n",
        "\n",
        "\n",
        "vaegan.draw_manifold(0)\n",
        "vaegan.draw_manifold(1)\n",
        "vaegan.draw_manifold(2)\n",
        "vaegan.draw_manifold(3)\n",
        "vaegan.draw_manifold(4)\n",
        "vaegan.draw_manifold(5)\n",
        "vaegan.draw_manifold(6)\n",
        "vaegan.draw_manifold(7)\n",
        "vaegan.draw_manifold(8)\n",
        "vaegan.draw_manifold(9)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) =fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test  = x_test .astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))\n",
        "y_train_cat = to_categorical(y_train).astype(np.float32)\n",
        "y_test_cat  = to_categorical(y_test).astype(np.float32)\n",
        "\n",
        "vaegan = VAEGAN(digit_size, num_classes, latent_dim)\n",
        "vaegan.train(x_train, y_train_cat, batch_size, epochs, 5)\n",
        "\n",
        "\n",
        "vaegan.draw_manifold(0)\n",
        "vaegan.draw_manifold(1)\n",
        "vaegan.draw_manifold(2)\n",
        "vaegan.draw_manifold(3)\n",
        "vaegan.draw_manifold(4)\n",
        "vaegan.draw_manifold(5)\n",
        "vaegan.draw_manifold(6)\n",
        "vaegan.draw_manifold(7)\n",
        "vaegan.draw_manifold(8)\n",
        "vaegan.draw_manifold(9)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}